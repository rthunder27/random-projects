{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The intent behind this notebook was to calculate additional features that'd be a pain to do in tableau.\n",
    "Currently this is just the win-rates and pick-rates.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "#data=req.json()\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move this and other paramters to separate file\n",
    "support_heroes={'Ana','Baptiste','Brigette','Lucio','Mercy','Moira','Zenyatta'}\n",
    "tank_heroes={'D.Va','Orisa','Reinhart','Roadhog','Sigma','Winston','Wrecking Ball','Zarya'}\n",
    "damage_heroes={'Ashe',\n",
    " 'Bastion',\n",
    " 'Doomfist',\n",
    " 'Echo',\n",
    " 'Genji',\n",
    " 'Hanzo',\n",
    " 'Junkrat',\n",
    " 'McGree',\n",
    " 'Mei',\n",
    " 'Pharah',\n",
    " 'Reaper',\n",
    " 'Soldier: 76',\n",
    " 'Sombra',\n",
    " 'Symmetra',\n",
    " 'Torbjorn',\n",
    " 'Tracer',\n",
    " 'Widowmaker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path='C:\\\\Users\\\\Matt\\\\OneDrive\\\\'\n",
    "custom_date_parser = lambda x: datetime.strptime(x, \"%Y_%m_%d\")\n",
    "pivoted_ow_df=pd.read_csv(log_path+'full_comp_stats_running.csv', \n",
    "                          parse_dates=['date'],\n",
    "                          index_col=('player','hero','date'),\n",
    "                          date_parser=custom_date_parser)\n",
    "# pivoted_ow_df=pd.read_csv(log_path+'full_comp_stats_running.csv', \n",
    "\n",
    "#                           index_col=('player','hero','date'),\n",
    "# )\n",
    "pivoted_ow_df.sort_index(inplace=True)\n",
    "#1/11/2021, why did I reset the index. Could/should have just operated on it that form.\n",
    "new_df=pivoted_ow_df.reset_index()\n",
    "#new_df['date']=pd.to_datetime(new_df['date'],format='%Y_%m_%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this for squad, then start looking at 3 cases- when all role losses or wins in day, or when equal.\n",
    "cols=['Time Played',\n",
    "'Games Lost',\n",
    "'Games Tied',\n",
    "'Games Won',\n",
    "'Games Played']\n",
    "roles=['Damage','Tank','Support']\n",
    "class OW_player_analysis():\n",
    "    def __init__(self,df):\n",
    "        #df is full pivoted table for one player\n",
    "        self.df=df\n",
    "        self.all_heroes=df[df['hero']=='All Heroes'].set_index('date').sort_index()#.dropna(axis=1,how='all')\n",
    "        self.sr_diff=self.all_heroes[['Tank SR','Support SR','Damage SR','Games Played']].diff()\n",
    "    def specific_hero_diff(self,hero):\n",
    "        hero_df=self.df[self.df['hero']==hero].set_index('date').sort_index().dropna(axis=1,how='all').drop(['player','hero'],axis=1)\n",
    "        hero_diff_df=hero_df.diff()\n",
    "        #Consider adding code here to fix the discontinuity between seasons\n",
    "        return hero_df,hero_diff_df\n",
    "    def check_role_changes(self):\n",
    "        \"\"\"\n",
    "        What are we doing here? \n",
    "        What do we want? Support/tank/dps games played/won/lost/tied/time, along with SR changes\n",
    "        \n",
    "        Net positive avg change, net negative avg change, net neutral avg change\n",
    "        \n",
    "        Looks like a +29 for a net 0 on support for me on 5/15, which is not feasible. But this is not an error\n",
    "        in my code, that's how it is in the html files.\n",
    "        Also Net - Tank SR seems too low for 5/15, consider dropping that day\n",
    "        \n",
    "        Berg's 4/29 also makes no sense, a -29 despite having a new win. Dropped game? \n",
    "        Add sanity checks, if net 0 change>15, net pos<10, net negative>-10\n",
    "        \"\"\"\n",
    "        self.support=self.df.loc[new_df['hero'].isin(support_heroes),cols+['date']].groupby('date').sum().add_suffix(' Support')\n",
    "        self.support_dff=self.support.sort_index().diff()\n",
    "        \n",
    "        self.damage=self.df.loc[new_df['hero'].isin(damage_heroes),cols+['date']].groupby('date').sum().add_suffix(' Damage')\n",
    "        self.damage_dff=self.damage.sort_index().diff()\n",
    "        \n",
    "        self.tank=self.df.loc[new_df['hero'].isin(tank_heroes),cols+['date']].groupby('date').sum().add_suffix(' Tank')\n",
    "        self.tank_dff=self.tank.sort_index().diff()\n",
    "        \n",
    "        \n",
    "        self.all_roles=self.support.join(self.damage).join(self.tank,rsuffix='tank')\n",
    "        self.all_roles_dff=self.all_roles.sort_index().diff()\n",
    "        self.all_roles_dff_sr=self.all_roles_dff.join(self.sr_diff)\n",
    "        for role in roles:\n",
    "            self.all_roles_dff_sr[f\"Net {role} Games\"]=self.all_roles_dff_sr[f\"Games Won {role}\"]-self.all_roles_dff_sr[f\"Games Lost {role}\"]\n",
    "            net_pos_mask=((self.all_roles_dff_sr[f\"Net {role} Games\"]>0) &(self.all_roles_dff_sr[f\"Games Won {role}\"]>0) )\n",
    "            net_neg_mask=((self.all_roles_dff_sr[f\"Net {role} Games\"]<0) &(self.all_roles_dff_sr[f\"Games Lost {role}\"]>0) )\n",
    "            net_zero_mask=((self.all_roles_dff_sr[f\"Net {role} Games\"]==0) &(self.all_roles_dff_sr[f\"Games Won {role}\"]>0) )\n",
    "            self.all_roles_dff_sr.loc[net_pos_mask,f'Net + SR {role}']=self.all_roles_dff_sr.loc[net_pos_mask,f\"{role} SR\"]/self.all_roles_dff_sr.loc[net_pos_mask,f\"Net {role} Games\"]\n",
    "            self.all_roles_dff_sr.loc[net_neg_mask,f'Net - SR {role}']=self.all_roles_dff_sr.loc[net_neg_mask,f\"{role} SR\"]/self.all_roles_dff_sr.loc[net_neg_mask,f\"Net {role} Games\"]\n",
    "            self.all_roles_dff_sr.loc[net_zero_mask,f'Net 0 SR {role}']=self.all_roles_dff_sr.loc[net_zero_mask,f\"{role} SR\"]/self.all_roles_dff_sr.loc[net_zero_mask,f\"Games Won {role}\"]\n",
    "            #Sanity checks. SR change <12, >40 unreasonable? \n",
    "            self.all_roles_dff_sr.loc[self.all_roles_dff_sr[f'Net + SR {role}']>40,f'Net + SR {role}']=np.nan\n",
    "            self.all_roles_dff_sr.loc[self.all_roles_dff_sr[f'Net + SR {role}']<12,f'Net + SR {role}']=np.nan\n",
    "            self.all_roles_dff_sr.loc[self.all_roles_dff_sr[f'Net - SR {role}']>40,f'Net - SR {role}']=np.nan\n",
    "            self.all_roles_dff_sr.loc[self.all_roles_dff_sr[f'Net - SR {role}']<12,f'Net - SR {role}']=np.nan\n",
    "            self.all_roles_dff_sr.loc[self.all_roles_dff_sr[f'Net 0 SR {role}'].abs()>15,f'Net 0 SR {role}']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So what do we want to do?\n",
    "\"\"\"\n",
    "Per player/role, show how win percentages change over time for various heroes within that role. \n",
    "While you could simply use the win-percentage as is, that's tied to the season. Could instead do it as a rolling average of X\n",
    "number of games played with that hero, say 10.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay, this seems to work. Consider making the window size a parameter\n",
    "def get_rolling_wr(m_df_slim,pivoted_ow_df,hero,player):\n",
    "    played_list=[]\n",
    "    won_list=[]\n",
    "    min_window_size=25\n",
    "    max_window_size=40\n",
    "    out_series=pd.Series(dtype='float64')\n",
    "    m_df_slim.fillna(value=0,inplace=True)\n",
    "    for index, row in m_df_slim.iterrows():\n",
    "        if row['Games Played']>=0:\n",
    "            played_list.append(row['Games Played'])\n",
    "            won_list.append(row['Games Won'])\n",
    "        if sum(played_list)>min_window_size:\n",
    "            while sum(played_list)>max_window_size:\n",
    "                #Perhaps add a check to make sure removing the next one doesn't drop below the min threshold\n",
    "                played_list=played_list[1:]\n",
    "                won_list=won_list[1:]\n",
    "            win_rate=sum(won_list)/sum(played_list)*100\n",
    "            out_series.loc[index]=win_rate\n",
    "            \n",
    "#Kinda surprised I never hit any index errors with this. Makes sense though, it's operating off of the character\n",
    "#specific series.\n",
    "    pivoted_ow_df.loc[(player,hero,slice(out_series.index[0],out_series.index[-1])),'Win Rate']=out_series.values\n",
    "    return out_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pick_rates(pr_df,pivoted_ow_df,player,missing_index_dict):\n",
    "    played_list=[]\n",
    "    index_list=[]\n",
    "    min_window_size=25\n",
    "    max_window_size=40\n",
    "    hero_cols=[col for col in pr_df.columns if col!=f'{role} played' ]\n",
    "    out_df=pd.DataFrame()\n",
    "    index_dict={}\n",
    "    pr_dict={}\n",
    "    \n",
    "    for hero in hero_cols:\n",
    "        pr_dict[hero]=[]\n",
    "        index_dict[hero]=[]\n",
    "    for index, row in pr_df.iterrows():\n",
    "        if row[f'{role} played']>=0:\n",
    "            played_list.append(row[f'{role} played'])\n",
    "            index_list.append(index)\n",
    "        if sum(played_list)>min_window_size:\n",
    "            while sum(played_list)>max_window_size:\n",
    "                #Perhaps add a check to make sure removing the next one doesn't drop below the min threshold\n",
    "                played_list=played_list[1:]\n",
    "                index_list=index_list[1:]\n",
    "            for hero in hero_cols:\n",
    "                pr=sum(pr_df.loc[index_list[0]:index_list[-1],hero])/sum(played_list)*100\n",
    "                #series_dict[hero].loc[index]=pr\n",
    "                #pivoted_ow_df.loc[(player,hero,index),'Pick Rate']=pr\n",
    "                if index in pivoted_ow_df.loc[(player,hero)].index:pivoted_ow_df.loc[(player,hero,index),'Pick Rate']=pr\n",
    "                else:missing_index_dict[(player,hero,index)]=pr\n",
    "                    \n",
    "                    \n",
    "    \"\"\"\n",
    "    1/13/2021 5pm\n",
    "    So apparently the reason for the slow performance, index unsorted error was caused by try to insert data into a \n",
    "    date for which that particular hero had no info, it's creating a new row. Simply checking to see if the index existed fixes\n",
    "    this. Now won't this cause issues, because of how the rolling window works between seasons, you'll have a non-zero pick rate\n",
    "    be omitted from the data. Let's see when we work with it in Tableau. \n",
    "    An easy fix might to up at the top go through and add all the missing day/hero/combinations, which would increase the size of the\n",
    "    DF, but not too large. \n",
    "    Never did chase down why the slice method was failing for my Junkrat data, but it seems moot now. Let's table this for now\n",
    "    and work on Tableau.\n",
    "    \n",
    "    \"\"\"                    \n",
    "                    \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.332566022872925\n",
      "5.710983991622925\n",
      "3.1319241523742676\n",
      "3.5163800716400146\n",
      "6.447938680648804\n",
      "0.6447956562042236\n",
      "1.1386241912841797\n"
     ]
    }
   ],
   "source": [
    "squad=['Rthunder27','BIGoleICEBERG','Seraph341','LaCroixDaddy','YAS RIHANNA','star4ker','ULove2SeeIt7915']\n",
    "missing_index_dict=dict()\n",
    "#player='Rthunder27'\n",
    "for player in squad:\n",
    "    t0=time.time()\n",
    "    t=OW_player_analysis(new_df.loc[new_df['player']==player])\n",
    "    role_dict={'Tank':tank_heroes,'Support':support_heroes,'DPS':damage_heroes}\n",
    "    for role in role_dict:\n",
    "        pivoted_ow_df.sort_index(inplace=True)\n",
    "        pr_df=pd.DataFrame()\n",
    "        wr_df=pd.DataFrame()\n",
    "        for hero in role_dict[role]:\n",
    "            try:\n",
    "                m,m_df=t.specific_hero_diff(hero)\n",
    "            except:continue\n",
    "                #Yes, this means that the first games played with a hero each season will be ignored. need better way to fix season change discontinuities\n",
    "            pr_df[hero]=m_df['Games Played'].apply(lambda x: 0 if x<0 else x)\n",
    "\n",
    "            try:\n",
    "                wr_series=get_rolling_wr(m_df,pivoted_ow_df,hero,player)\n",
    "\n",
    "            except:continue\n",
    "        pr_df.fillna(value=0,inplace=True)\n",
    "        pr_df[f'{role} played']=pr_df.sum(axis=1)   \n",
    "        get_pick_rates(pr_df,pivoted_ow_df,player,missing_index_dict)\n",
    "\n",
    "    print((time.time()-t0))\n",
    "missing_indices_df=pd.DataFrame(index=missing_index_dict.keys(),data=missing_index_dict.values(),columns=['Pick Rate'])\n",
    "ow_df_w_missings=pd.concat([pivoted_ow_df,missing_indices_df])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/26 Add in logic to fill missings in SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ow_df_w_missings.to_csv('full_comp_with_rates_2021-01-25.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}